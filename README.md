# Triton B64 Example

A basic example of how to pass a base64-encoded JPEG image into an [NVIDIA Triton](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/introduction/index.html) model (because I found this surprisingly annoying to figure out).

> NOTE: Initial example code generated by GPT-5 before being tested and cleaned up by me.

## The important bits I learned

-   Data types: your request with the base64 image should be set to `BYTES`, while the Triton server config should set the input to `TYPE_STRING`. This was my biggest confusion (I initially thought they should both be set to the same thing).
-   The request's `data` field should be an array with a string in it, like so: `"data": ["myb64data..."]` - 
-   The Triton config file should expect an input shape of `[1]` (i.e. each batch is a 1D array with exactly 1 string element - that string element can be of arbitrary size). Your request shape should be `[1]` - UNLESS you're using batching...
-   If `max_batch_size` > 0 in your Triton config, you're using batching. You'll need to include the batch size in your requests, and modify `model.py` to handle the batches. On the request side, you can do this in by changing the size to `[batch_size, 1]` and nesting your `data` arrays with however many images you want to send in the batch: `[[img1_b64], [img2_b64], ...]`. On the model side, a single request's `in_tensor.numpy()` will now return an array with shape `[batch_size, 1]`, which the model will need to handle accordingly.
    -   `max_batch_size: 0` seems to be a special case where `in_tensor.numpy()` will just return a 1D array, not a 2D array containing each 1D-batch. In this case, nesting the data arrays isn't necessary.


## How to run this

First, you'll need both [Docker](https://www.docker.com/get-started/) and [uv](https://docs.astral.sh/uv/getting-started/) installed. Then,

1.  Start the Triton server.

    ```sh
    docker build -t triton-b64-example:latest .
    docker run --rm -p 8000:8000 -p 8001:8001 -p 8002:8002 -v "$(pwd)/triton_models:/models" triton-b64-example
    ```

    > NOTE: The Triton docker image is several GB in size, and might take a few minutes to download

2.  In a separate tab, run `uv run main.py` to make a request (converts `test.jpeg` to base64, sends a request in the right format, and prints the response).
